---
permalink: /publications/
title: "Publications"
excerpt: "Publications"
author_profile: true
---
You may also find my recent articles on [Google
Scholar](https://scholar.google.co.kr/citations?user=Py4URJUAAAAJ&hl=en).

## Preprints
- [Over-parameterised shallow neural networks with asymmetrical node scaling: global convergence guarantees and feature learning](https://arxiv.org/abs/2302.01002)\\
Francois Caron, Fadhel Ayed, Paul Jung, Hoil Lee, **Juho Lee**, Hongseok Yang

- [Deep neural networks with dependent weights: Gaussian process mixture limit, heavy tails, sparsity and compressibility](https://arxiv.org/abs/2205.08187)\\
Hoil Lee, Fadhel Ayed, Paul Jung, **Juho Lee**, Hongseok Yang, François Caron

- [Hybrid generative-contrastive representation learning](https://arxiv.org/abs/2106.06162)\\
Saehoon Kim, Sungwoong Kim, **Juho Lee**

- [Learning to pool in graph neural networks for extrapolation](https://arxiv.org/abs/2106.06210)\\
Jihoon Ko, Taehyung Kwon, Kijung Shin, **Juho Lee**

- [Deep amortized clustering](https://arxiv.org/abs/1909.13433)\\
**Juho Lee**, Yoonho Lee, Yee Whye Teh\\
A preliminary version of this work has been accepted to [NeurIPS 2019 Sets & Partitions workshop](https://www.sets.parts) as an oral presentation.

- [Adaptive network sparsification with dependent variational beta-Bernoulli dropout](https://arxiv.org/abs/1805.10896v3)\\
**Juho Lee**, Saehoon Kim, Jaehong Yoon, Hae Beom Lee, Eunho Yang, Sung Ju Hwang

## Journals
- [The Normal-Generalised Gamma-Pareto process: A novel pure-jump Lévy process with flexible tail and jump-activity properties
](https://arxiv.org/abs/2006.10968) \\
Fadhel Ayed, **Juho Lee**, François Caron\\
To appear in Bayesian Anaylsis

- [Benefits of stochastic weight averaging in developing neural network radiation scheme for numerical weather prediction](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2021MS002921?af=R)\\
Hwan-Jin Song, Soonyoung Roh, **Juho Lee**, Giung Nam, Eunggu Yun, Jongmin Yoon, Park Sa Kim\\
Journal of Advances in Modeling Earth Systems, October 2022


- [A unified construction for series representations and finite approximations of completely random measures](https://arxiv.org/abs/1905.10733)\\
**Juho Lee**, Xenia Miscouridou, François Caron\\
To appear in Bernoulli

## Conferences

- Probabilistic imputation for time-series classification with missing data \\
SeungHyun Kim\*, Hyunsu Kim\*, Eunggu Yun\*, Hwangrae Lee, Jaehun Lee, **Juho Lee** \\
(*: Equal Contribution)\\
To appear in ICML 2023

- Traversing between modes in function space for fast ensembling \\
Eunggu Yun\*, Hyungi Lee\*, Giung Nam\*, **Juho Lee**\\
(*: Equal Contribution)\\
To appear in ICML 2023

- Regularizing towards soft equivariance under mixed symmetries \\
Hyunsu Kim, Hyungi Lee, Hongseok Yang, **Juho Lee**\\
To appear in ICML 2023

- Scalable set encoding with universal mini-batch consistency and unbiased full set gradient approximation \\
Jeffrey Ryan Willette\*, Seanie Lee\*, Bruno Andreis, Kenji Kawaguchi, **Juho Lee**, Sung Ju Hwang \\
(*: Equal Contribution)\\
To appear in ICML 2023


- [Martingale posterior neural processes](https://openreview.net/forum?id=-9PVqZ-IR_) \\
Hyungi Lee, Eunggu Yun, Giung Nam, Edwin Fong, **Juho Lee**\\
ICLR 2023 (**Notable top 25%**)

- [Decoupled training for long-tailed classification with stochastic representations](https://openreview.net/forum?id=bcYZwYo-0t)\\
Giung Nam\*, Sunguk Jang\*, **Juho Lee**\\
(*: Equal Contribution)\\
ICLR 2023

- [A simple yet powerful deep active learning with snapshot ensembles](https://openreview.net/forum?id=IVESH65r0Ar)\\
Seohyeon Jung\*, Sanghyun Kim\*, **Juho Lee**\\
(*: Equal Contribution)\\
ICLR 2023

- [Self-distillation for further pre-training of transformers](https://openreview.net/forum?id=kj6oK_Hj40)\\
Seanie Lee, Minki Kang, **Juho Lee**, Sung Ju Hwang, Kenji Kawaguchi\\
ICLR 2023

- [Exploring the role of mean teachers in self-supervised masked auto-encoders](https://openreview.net/forum?id=7sn6Vxp92xV)\\
Youngwan Lee\*, Jeffrey Ryan Willette\*, Jonghee Kim, **Juho Lee**, Sung Ju Hwang \\
(*: Equal Contribution)\\
ICLR 2023

- [On divergence measures for Bayesian pseudocoresets](https://arxiv.org/abs/2210.06205)\\
Balhae Kim, Jungwon Choi, Seanie Lee, Yoonho Lee, Jung-Woo Ha, **Juho Lee**\\
NeurIPS 2022

- [Set-based meta-interpolation for few-task meta-learning](https://arxiv.org/abs/2205.09990)\\
Seanie Lee, Bruno Andreis, Kenji Kawaguchi, **Juho Lee**, Sung Ju Hwang\\
NeurIPS 2022

- [Improving ensemble distillation with weight averaging and diversifying perturbation](https://proceedings.mlr.press/v162/nam22a.html)\\
Giung Nam, Hyungi Lee, Byeongho Heo, **Juho Lee**\\
ICML 2022\\
[Code](https://github.com/cs-giung/distill-latentbe)

- [Set based stochastic subsampling](https://proceedings.mlr.press/v162/andreis22a.html)\\
Bruno Andreis, Seanie Lee, A. Tuan Nguyen, **Juho Lee**, Eunho Yang, Sung Ju Hwang\\
ICML 2022

- [Scale mixtures of neural network Gaussian processes](https://arxiv.org/abs/2107.01408)\\
Hyungi Lee, Eunggu Yoon, Hongseok Yang, **Juho Lee**\\
ICLR 2022

- [Sequential Reptile: inter-task gradient alignment for multilingual learning](https://arxiv.org/abs/2110.02600)\\
Seanie Lee, Hae Beom Lee, **Juho Lee**, Sung Ju Hwang\\
ICLR 2022

- [Meta learning low rank covariance factors for energy-based deterministic uncertainty](https://arxiv.org/abs/2110.06381)\\
Jeffrey Ryan Willette, Hae Beom Lee, **Juho Lee**, Sung Ju Hwang\\
ICLR 2022

- [Diversity matters when learning from ensembles](https://arxiv.org/abs/2110.14149)\\
Giung Nam\*, Jongmin Yoon\*, Yoonho Lee, **Juho Lee**\\
(*: Equal Contribution)\\
NeurIPS 2021\\
[Code](https://github.com/cs-giung/giung2/tree/main/projects/Diversity-Matters)

- [Mini-batch consistent slot set encoder for scalable set encoding](https://arxiv.org/abs/2103.01615)\\
Bruno Andreis, Jeffrey Ryan Willette, **Juho Lee**, Sung Ju Hwang\\
NeurIPS 2021

- [A multi-mode modulator for multi-domain few-shot classification](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_A_Multi-Mode_Modulator_for_Multi-Domain_Few-Shot_Classification_ICCV_2021_paper.html)\\
Yanbin Liu, **Juho Lee**, Linchao Zhu, Ling Chen, Humphrey Shi, Yi Yang\\
ICCV 2021

- [Adversarial purification with score-based generative models](https://arxiv.org/abs/2106.06041) \\
Jongmin Yoon, Sung Ju Hwang, **Juho Lee**\\
ICML 2021 \\
[Code](https://github.com/jmyoon1/adp)

- [Learning to perturb word embeddings for out-of-distribution QA](https://arxiv.org/abs/2105.02692) \\
Seanie Lee, Minki Kang, **Juho Lee**, Sung Ju Hwang\\
ACL 2021

- [SetVAE: learning hierarchical composition for generative modeling of set-structured data](https://arxiv.org/abs/2103.15619)\\
Jinwoo Kim, Jaehoon Yoo, **Juho Lee**, Seunghoon Hong\\
CVPR 2021\\
[Code](https://github.com/jw9730/setvae)

- [Bootstrapping neural processes](https://arxiv.org/abs/2008.02956)\\
**Juho Lee**\*, Yoonho Lee\*, Jungtaek Kim, Eunho Yang, Sung Ju Hwang, Yee Whye Teh\\
(*: Equal Contribution)\\
[Code](https://github.com/juho-lee/bnp)\\
NeurIPS 2020

- [Neural complexity measures](https://arxiv.org/abs/2008.02953)\\
Yoonho Lee, **Juho Lee**, Sung Ju Hwang, Eunho Yang, Seungjin Choi\\
[Code](https://github.com/yoonholee/neural-complexity)\\
NeurIPS 2020

- [Cost-effective interactive attention learning with neural attention processes](https://arxiv.org/abs/2006.05419)\\
Jay Heo, Junhyeon Park, Hyewon Jeong, Kwang Joon Kim, **Juho Lee**, Eunho Yang, Sung Ju Hwang\\
ICML 2020

- [Deep mixed effect model using Gaussian processes: a personalized and reliable prediction for
  healthcare](https://arxiv.org/abs/1806.01551)\\
Ingyo Chung, Saehoon Kim, **Juho Lee**, Sung Ju Hwang, Eunho Yang\\
AAAI 2020

- [Beyond the Chinese restaurant and Pitman-Yor processes: statistical models with double power-law behavior](https://arxiv.org/abs/1902.04714)\\
Fadhel Ayed\*, **Juho Lee**\*, and François Caron\\
(*: Equal Contribution)\\
ICML 2019 (**long oral presentation**)

- [Set transformer: a framework for attention-based permutation-invariant neural networks](https://arxiv.org/abs/1810.00825v3)\\
**Juho Lee**, Yoonho Lee, Jungtaek Kim, Adam R. Kosiorek, Seungjin Choi, and Yee Whye Teh\\
[Code](https://github.com/juho-lee/set_transformer)\\
ICML 2019

- [Learning to propagate labels: transductive propagation network for few-shot learning](https://arxiv.org/abs/1805.10002)\\
Yanbin Liu, **Juho Lee**, Minseop Park, Saehoon Kim, Eunho Yang, Sung Ju Hwang and Yi Yang\\
ICLR 2019

- [A Bayesian model for sparse graphs with flexible degree distribution and overlapping community structure](https://arxiv.org/abs/1810.01778)\\
**Juho Lee**, Lancelot F. James, Seungjin Choi, and François Caron\\
AISTATS 2019 (**oral presentation**)\\
[Code](https://github.com/OxCSML-BayesNP/BNRG)

- [Uncertainty-aware attention for reliable interpretation and prediction](https://arxiv.org/abs/1805.09653)\\
Jay Heo\*, Hae Beom Lee\*, Saehoon Kim, **Juho Lee**, Kwang Joon Kim, Eunho Yang, and Sung Ju
Hwang\\
(*: Equal Constribution)\\
NeurIPS 2018

- [Dropmax: adaptive variational softmax](https://arxiv.org/abs/1712.07834)\\
Hae Beom Lee, **Juho Lee**, Saehoon Kim, Eunho Yang, and Sung Ju Hwang\\
NeurIPS 2018\\
[Code](https://github.com/haebeom-lee/dropmax)

- [Bayesian inference on random simple graphs with power law degree distributions](http://proceedings.mlr.press/v70/lee17a.html)\\
**Juho Lee**, Creighton Heakulani, Zoubin Ghahramani, Lancelot F. James, and Seingjin Choi\\
ICML 2017\\
[Code](https://github.com/juho-lee/powerlawgraph)

- [Finite-dimensional BFRY priors and variational Bayesian inference for power law models](https://papers.nips.cc/paper/6348-finite-dimensional-bfry-priors-and-variational-bayesian-inference-for-power-law-models)\\
**Juho Lee**, Lancelot F. James, and Seungjin Choi\\
NIPS 2016

- [Tree-guided MCMC inference for normalized random measure mixture models](https://papers.nips.cc/paper/5800-tree-guided-mcmc-inference-for-normalized-random-measure-mixture-models)\\
**Juho Lee** and Seungjin choi\\
NIPS 2015\\
[Code](https://github.com/juho-lee/nrmm.cpp)

- [Bayesian hierarchical clustering with exponential family: small-variance asymptotics and reducibility](http://proceedings.mlr.press/v38/lee15c.html)\\
**Juho Lee** and Seungjin Choi\\
AISTATS 2015

- [Incremental tree-based inference with dependent normalized random measures](http://proceedings.mlr.press/v33/lee14.html)\\
**Juho Lee** and Seungjin Choi\\
AISTATS 2014

- [Online video segmentation by Bayesian split-merge clustering](https://link.springer.com/chapter/10.1007/978-3-642-33765-9_61)\\
**Juho Lee**, Suha Kwak, Bohyung Han, and Seungjin Choi\\
ECCV 2012

## Workshops
- [Towards safe self-distillation of internet-scale text-to-image diffusion models](https://arxiv.org/pdf/2307.05977.pdf)\\
Sanghyun Kim, Seohyeon Jung, Balhae Kim, Moonseok Choi, Jinwoo Shin, **Juho Lee**\\
ICML 2023 Workshop on Challenges in Deployable Generative AI, 2023

- [Modeling uplift from observational time-series in continual scenarios](https://openreview.net/forum?id=pKyB5wMnTiy)\\
Sanghyun Kim, Jungwon Choi, NamHee Kim, Jaesung Ryu, **Juho Lee**\\
AAAI23 Bridge on Continual Casality (**oral presentation**), 2023

- [Fine-tuning Diffusion Models with Limited Data](https://openreview.net/forum?id=0J6afk9DqrR)\\
Taehong Moon, Moonseok Choi, Gayoung Lee, Jung-Woo Ha, **Juho Lee**\\
NeurIPS 2022 Workshop on Score-Based Methods, 2022

- [Adaptive strategy for resetting a non-stationary Markov chain during learning via joint stochastic optimization](https://openreview.net/forum?id=fuHh4CC3-5Z)\\
Hyunsu Kim, **Juho Lee**, Hongseok Yang\\
Third Symposium on Advances in Approximate Bayesian Inference, 2021

- [Towards deep amortized clustering](https://slideslive.com/38923511/contributed-talk-towards-deep-amortized-clustering)\\
**Juho Lee**, Yoonho Lee, Yee Whye Teh\\
NeurIPS 2019 Sets & Partitions workshop (**contributed talk**), 2019

- [Graph embedding VAE: a permutation invariant model of graph structure](https://grlearning.github.io/papers/19.pdf)\\
Tony Duan, **Juho Lee**\\
NeurIPS 2019 Graph Representation Learning workshop, 2019
